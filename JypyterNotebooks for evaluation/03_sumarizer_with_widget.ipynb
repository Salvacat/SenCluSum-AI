{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import pandas as pd\n",
    "from transformers import LlamaTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "# Log in to Hugging Face with your token\n",
    "huggingface_token = \"Add your token here\"\n",
    "login(token=huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install ipwidgets if needed\n",
    "#! pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e6de6b182540878980c294015185fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e86367275e34d4b8ed6d5bebda70048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d191c0517e24afea5ec774155b0c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d30b91633eb4da6b4aed400009886bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50917c4b51642cd9d33bdabf4b48072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b530802bf13b4a45b60f985e351f386a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7dece520bc443faeaabf502a55063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d25d97ff2243388f3a37e22d6814df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b05e63d1814dd7b411341542c4b038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4fb7404ee34d3198ecce9f6e1f4d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328bb62b295b43f69ec353826ab1ed2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a70a7e682742d9a618dfd7d66cb8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32768, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Use LlamaTokenizer for Mistral models, as Mistral is compatible with LLaMA tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is loaded onto the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and drop unnecessary columns\n",
    "csv_file = \"filtered_data_predictions_clusters.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.drop(columns=[\"brand\", \"categories\", \"primaryCategories\", \"reviews.date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cluster names for user-friendly selection\n",
    "cluster_names = {\n",
    "    0: \"Smart Speakers\",\n",
    "    1: \"Pet Supplies & AAA Batteries\",\n",
    "    2: \"Fire Tablets & Streaming Devices with Alexa\",\n",
    "    3: \"Fire Tablets - Standard Editions\",\n",
    "    4: \"Fire Tablets - Kids Editions\",\n",
    "    5: \"Fire Tablets with Alexa\",\n",
    "    6: \"Alexa Devices & Accessories\",\n",
    "    7: \"AA Batteries\",\n",
    "    8: \"Kindle E-Readers & Accessories\",\n",
    "    9: \"Echo Devices - Various Generations\"\n",
    "}\n",
    "\n",
    "# Add cluster name column\n",
    "df['category_name'] = df['cluster'].map(cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific promptreview summaries\n",
    "review_prompt_template = \"Provide a two-sentence summary of the main strengths and weaknesses for this product based on user reviews: {}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_product_summaries(results):\n",
    "    print(\"\\n Here are the top products of the category:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, entry in enumerate(results, 1):\n",
    "        print(f\"\\nProduct Name: {entry['product_name']}\")\n",
    "        print(f\"Title Summary:\\n  {entry['title_summary']}\")\n",
    "        print(f\"Review Summary:\\n  {entry['review_summary']}\")\n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(prompt, max_new_tokens=20, temperature=0.5, repetition_penalty=1.8, is_title=False):\n",
    "    # Adjust parameters for titles\n",
    "    if is_title:\n",
    "        max_new_tokens = 50  # Increase slightly for more complete titles\n",
    "        repetition_penalty = 1.8  # Reduce redundancy\n",
    "        temperature=5\n",
    "\n",
    "    # Generate title or summary\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        num_beams=3,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and return output\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synonyms for variety\n",
    "synonyms = {\n",
    "    \"great\": [\"excellent\", \"outstanding\", \"impressive\"],\n",
    "    \"good\": [\"satisfactory\", \"decent\", \"suitable\"],\n",
    "    \"easy\": [\"straightforward\", \"simple\", \"user-friendly\"],\n",
    "    \"awesome\": [\"fantastic\", \"remarkable\", \"incredible\"],\n",
    "    \"price\": [\"cost\", \"value\", \"affordability\"],\n",
    "}\n",
    "def post_process(text):\n",
    "    # Patterns for prompt artifacts\n",
    "    prompt_patterns = [\n",
    "        r\"^Create a one-sentence title summarizing.*:?\\s*\",\n",
    "        r\"^Provide a two-sentence summary.*:?\\s*\",\n",
    "        r\"^Focus on unique qualities only.*:?\\s*\",\n",
    "        r\"^Generate a 5-word title that summarizes the key.*:?\\s\",\n",
    "        r\"^.*summarizing.*:\\s*\",  # Remove 'summarizing' patterns\n",
    "        r\"^.*summary.*:\\s*\",      # Remove 'summary' patterns\n",
    "        r\"^.*qualities only.*:\\s*\",  # Remove 'qualities only' patterns\n",
    "        r\"^.*summarizes the key.*:\\s*\",  # Remove 'summarizes the key' patterns\n",
    "        r\"^Strengths:\\s*\",  # Remove 'Strengths:' leading label\n",
    "        r\"^Weaknesses:\\s*\",  # Remove 'Weaknesses:' leading label\n",
    "        r\"\\s*Strengths:\\s*\",  # Remove 'Strengths:' inline label\n",
    "        r\"\\s*Example:\\s*\"  \n",
    "        r\"\\s*Review:\\s*\"\n",
    "        r\"^Examples?:\\s*\",          # Lines starting with \"Example:\" or \"Examples:\"\n",
    "        r\"^- Review\\s*:\\s*\",        # Lines starting with \"- Review:\"\n",
    "        r\"^Main Weaknesses?:\\s*\",   # Lines starting with \"Main Weaknesses:\"\n",
    "        r\"^\\d+\\.\",                  # Removes any numbered lists at the start of a line (e.g., \"1.\")\n",
    "        r\"^-\",                      # Removes lines starting with a dash or hyphen\n",
    "        r\"^\\s*\"                     # Remove extra whitespace-only lines    \n",
    "    ]\n",
    "    \n",
    "    # Remove initial prompt text and track changes\n",
    "    for pattern in prompt_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Ensure text ends at the last complete sentence\n",
    "    last_period_index = text.rfind(\".\")\n",
    "    if last_period_index != -1:\n",
    "        text = text[:last_period_index + 1]   \n",
    "        \n",
    "    # Split into sentences and filter out fragments\n",
    "    sentences = re.split(r'(?<=\\w[.!?])\\s+', text)\n",
    "    sentences = [s for s in sentences if s and len(s.split()) > 3]\n",
    "    \n",
    "    # Synonym replacement for variety\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word, syn_list in synonyms.items():\n",
    "            if word in sentence:\n",
    "                synonym = random.choice(syn_list)\n",
    "                sentence = re.sub(r'\\b{}\\b'.format(word), synonym, sentence, flags=re.IGNORECASE)\n",
    "        sentences[i] = sentence\n",
    "    \n",
    "    # Add contextual phrases if applicable\n",
    "    final_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if \"kids\" in sentence.lower() or \"children\" in sentence.lower():\n",
    "            sentence += \" Ideal for young users due to its durable and easy-to-use design.\"\n",
    "        elif \"waterproof\" in sentence.lower() or \"beach\" in sentence.lower():\n",
    "            sentence += \" Perfect for reading outdoors or by the pool.\"\n",
    "        final_sentences.append(sentence)\n",
    "    \n",
    "    # Recombine the cleaned and enhanced sentences\n",
    "    processed_text = \" \".join(final_sentences)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_title(text):\n",
    "    # Locate the last occurrence of \"Title:\" and keep everything that follows\n",
    "    last_title_index = text.rfind(\"Title:\")\n",
    "    if last_title_index != -1:\n",
    "        text = text[last_title_index + len(\"Title:\"):].strip()\n",
    "\n",
    "    # Split text into lines for more precise line-by-line processing\n",
    "    lines = text.splitlines()\n",
    "    \n",
    "    # Patterns to remove unwanted artifacts from the title section\n",
    "    prompt_patterns = [\n",
    "        r\"^Examples?:\\s*$\",              # Removes \"Example:\" or \"Examples:\" lines\n",
    "        r\"^- Review\\s*:\\s*$\",            # Removes \"- Review:\" lines\n",
    "        r\"^Main Weaknesses?:\\s*$\",       # Removes \"Main Weaknesses:\" lines\n",
    "        r\"^Strengths?:\\s*$\",             # Removes \"Strengths:\" lines\n",
    "        r\"^\\d+\\.\\s*$\",                   # Removes any numbered lists (e.g., \"1. \")\n",
    "        r\"^-\\s*$\",                       # Removes lines starting with \"-\"\n",
    "        r\"^\\s*$\"                         # Removes empty lines\n",
    "    ]\n",
    "\n",
    "    # Remove lines that match any pattern\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        match = False\n",
    "        for pattern in prompt_patterns:\n",
    "            if re.match(pattern, line.strip(), re.IGNORECASE):\n",
    "                match = True\n",
    "                break\n",
    "        if not match:\n",
    "            cleaned_lines.append(line.strip())\n",
    "\n",
    "    # Join the cleaned lines back into a single text block\n",
    "    processed_text = \" \".join(cleaned_lines).strip()\n",
    "\n",
    "    # Remove any quotes and make sure to end with a complete sentence\n",
    "    processed_text = processed_text.strip('\\'\"')\n",
    "    processed_text = processed_text.rsplit('.', 1)[0] + '.'  # Ensure it ends with a complete sentence.\n",
    "\n",
    "    return processed_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_again(review_text, max_new_tokens=80):\n",
    "    # Set different generation parameters for more diversity and flexibility\n",
    "    temperature = 1.0  # Higher temperature for more varied responses\n",
    "    repetition_penalty = 1.2  # Lower penalty to allow a bit of repetition for emphasis\n",
    "\n",
    "    inputs = tokenizer(review_text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        num_beams=4,  # Increase beams for more options\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e4fb653c1f46debec6b22908f0d268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Category:', layout=Layout(width='max-content'), options=(('Smart Speakers', 0), ('Pet Suâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropdown selected value: 4\n",
      "fire kids edition tablet 7 display wifi 16 gb pink kidproof case\n",
      "\n",
      " Here are the top products of the category:\n",
      "============================================================\n",
      "\n",
      "Product Name: fire kids edition tablet 7 display wifi 16 gb pink kidproof case\n",
      "Title Summary:\n",
      "  Travel-Friendly, Kid-Proof Tablet.\n",
      "Review Summary:\n",
      "  The main strength of this product, according to user reviews, is that it is loved by 2-year-olds, making it a excellent tablet for kids when traveling. Ideal for young users due to its durable and easy-to-use design.\n",
      "============================================================\n",
      "\n",
      "Product Name: fire kids edition tablet 7 display wifi 16 gb pink kidproof case\n",
      "Title Summary:\n",
      "  User-Friendly and Durable: The Perfect E-Reader for Kids.\n",
      "Review Summary:\n",
      "  Based on user reviews, the main strength of the Kindle is its user-friendly interface, making it an ideal choice for children or those new to e-readers. Ideal for young users due to its durable and easy-to-use design.\n",
      "============================================================\n",
      "\n",
      "Product Name: fire kids edition tablet 7 display wifi 16 gb pink kidproof case\n",
      "Title Summary:\n",
      "  A Perfect Gift for Kids: Durable and User-Friendly Kindle.\n",
      "Review Summary:\n",
      "  The main strength of the Kindle, according to user reviews, is that it is highly appreciated by children, particularly a 9-year-old girl who received it as a Christmas Ideal for young users due to its durable and easy-to-use design.\n",
      "============================================================\n",
      "Dropdown selected value: 7\n",
      "amazonbasics aa performance alkaline batteries 48 count  packaging may vary\n",
      "\n",
      " Here are the top products of the category:\n",
      "============================================================\n",
      "\n",
      "Product Name: amazonbasics aa performance alkaline batteries 48 count  packaging may vary\n",
      "Title Summary:\n",
      "  Dependable Performance.\n",
      "Review Summary:\n",
      "  The main strength of this product, according to user reviews, is that it has provided them with reliable performance in the past.\n",
      "============================================================\n",
      "\n",
      "Product Name: amazonbasics aa performance alkaline batteries 48 count  packaging may vary\n",
      "Title Summary:\n",
      "  1. \"Amazing Battery Life and User-Friendly\" 2. \"Perfect for Kids, Durable, and Affordable\" 3.\n",
      "Review Summary:\n",
      "  \n",
      "============================================================\n",
      "\n",
      "Product Name: amazonbasics aa performance alkaline batteries 48 count  packaging may vary\n",
      "Title Summary:\n",
      "  Off-Brand Batteries: Hits and Misses.\n",
      "Review Summary:\n",
      "  Users who are fans of off-brand batteries have been generally pleased with their performance. Weaknesses: Some users who are not fans of off-brand batteries have been disappointed with their performance.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a dropdown widget for category selection\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=[(name, idx) for idx, name in cluster_names.items()],\n",
    "    description='Category:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': 'max-content'}\n",
    ")\n",
    "\n",
    "# Display the dropdown and retrieve the selected category\n",
    "display(dropdown)\n",
    "\n",
    "# Function to get selected category after user selects from dropdown\n",
    "def on_category_selected(change):\n",
    "    selected_category = change['new']\n",
    "    selected_category_name = cluster_names[selected_category]\n",
    "    print(\"Dropdown selected value:\", change['new'])  # Debugging line\n",
    "    \n",
    "    # Filter data for selected category\n",
    "    category_df = df[df['category_name'] == selected_category_name]\n",
    "    \n",
    "    # Implement filtering logic for top products based on your criteria\n",
    "    filtered_df = category_df[\n",
    "        (category_df['reviews.rating'].isin([1, 2, 3, 4, 5])) &\n",
    "        (category_df['predicted_sentiment'] == category_df['sentiment']) &\n",
    "        (\n",
    "            ((category_df['reviews.rating'].isin([1, 2])) & (category_df['sentiment'] == 'negative')) |\n",
    "            ((category_df['reviews.rating'] == 3) & (category_df['sentiment'] == 'neutral')) |\n",
    "            ((category_df['reviews.rating'].isin([4, 5])) & (category_df['sentiment'] == 'positive'))\n",
    "        )\n",
    "    ]\n",
    "    # Sort by appearances and rating, then select top 3 unique products by name\n",
    "    top_products = filtered_df.sort_values(\n",
    "        by=['appearances', 'reviews.rating'], \n",
    "        ascending=[False, False]\n",
    "    ).drop_duplicates(subset='name').head(3)\n",
    "    \n",
    "    # Generate summaries for the top products\n",
    "    results = []\n",
    "    for _, row in top_products.iterrows():\n",
    "        product_name = row[\"name\"]\n",
    "        combined_text = row[\"reviews.title\"] + \" \" + row[\"reviews.text\"]\n",
    "        review_prompt = review_prompt_template.format(combined_text[:150])\n",
    "        review_summary = generate_summary(review_prompt, max_new_tokens=60)\n",
    "        review_summary = post_process(review_summary)\n",
    "\n",
    "        # Check if summary is empty and regenerate if needed\n",
    "        if not review_summary:\n",
    "            # Use raw reviews text for regeneration to get a fresh perspective\n",
    "            review_prompt_2 = review_prompt_template.format(combined_text[150:300])\n",
    "            #review_text = row[\"reviews.text\"][:500]  # Use a larger chunk of raw text\n",
    "            review_summary = generate_summary(review_prompt_2, max_new_tokens=80)\n",
    "            print(product_name)\n",
    "            # Optional: Further post-process the regenerated summary if needed\n",
    "            review_summary = post_process(review_summary)\n",
    "\n",
    "        # Use an example-enhanced prompt for title generation\n",
    "        example_titles = \"\"\"\n",
    "        Examples:\n",
    "        - Review: \"This tablet has amazing battery life and is very user-friendly.\"\n",
    "        Title: \"Long Battery Life and Easy to Use\"\n",
    "        - Review: \"The Kindle Fire is perfect for kids, durable, and affordable.\"\n",
    "        Title: \"Kid-Friendly, Durable, and Affordable\"\n",
    "        - Review: \"Echo Show's sound quality is fantastic, but privacy concerns remain.\"\n",
    "        Title: \"Great Sound, But Privacy Concerns\"\n",
    "        \"\"\"\n",
    "\n",
    "        title_prompt_from_text = f\"\"\"{example_titles}\n",
    "        Create a concise and catchy title that captures the main idea of this review: {review_summary} Title:\n",
    "        \"\"\"\n",
    "        # Generate title based on the review summary with examples in the prompt\n",
    "        title_summary_raw = generate_summary(title_prompt_from_text, is_title=True)\n",
    "        #print(\"Title Before post-processing:\", title_summary_raw)\n",
    "\n",
    "        title_summary = post_process_title(title_summary_raw)\n",
    "        #print(\"Title after post-processing:\", title_summary)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"product_name\": product_name,\n",
    "            \"title_summary\": title_summary,\n",
    "            \"review_summary\": review_summary\n",
    "        })\n",
    "    top_product_summaries(results)\n",
    "\n",
    "# Link the dropdown selection to the function\n",
    "dropdown.observe(on_category_selected, names='value')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
